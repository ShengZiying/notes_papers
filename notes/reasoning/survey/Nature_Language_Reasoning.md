# Natural Language Reasoning, A Survey

**Author**: Fei Yu, Hongbo Zhang, Prayag Tiwari, Benyou Wang*

**Publish Date**: 2024

**Add Date**: 2025.11.2

**Journal/Meeting**: ACM Computing Surveys

**Star**: ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ

**PDF**: [Natural Language Reasoning, A Survey](original_files/Yu_2024_Natural_Language_Reasoning_A_Survey.pdf)

## 1 Introduction

![alt text](pics/image.png)

![alt text](pics/image1.png)

## 2 What is NLR

### 2.1 Definition

![alt text](pics/image2.png)

![alt text](pics/image3.png)

**Definition 2.4 (NLP Reasoning)**. NLR is a process to integrate multiple knowledge (e.g., encyclopedic knowledge and commonsense knowledge) to derive some new conclusions about the (realistic or hypothetical) world. Knowledge can be from both explicit and implicit sources. Conclusions are assertions or events assumed to be true in a world, or practical actions.

**Definition 2.5 (NLP Proposition)**. A proposition is the semantic meaning or information content of a statement rather than its superficial linguistics. (å‘½é¢˜)

**Definition 2.6 (NLP Inference)**. Inference is a single step that produces a single (intermediate) conclusion from some premises.

![alt text](pics/image4.png)

### 2.2 Categories of Inference

**Definition 2.7 (Deduction)**. A deductive inference is to infer valid knowledge (conclusion) from the given knowledge (premises).  (æ¼”ç»æ¨ç†)

**Definition 2.8 (Induction)**. An inductive inference is to infer probable knowledge, which describes a more general rule,5 extrapolated from the given knowledge.  (å½’çº³æ¨ç†)

**Definition 2.9 (Abduction)**. An abductive inference is to infer probable knowledge, as the best explanation (i.e., cause), for the given knowledge (i.e., phenomena).  (æº¯å› æ¨ç†)

| æ¨ç†ç±»å‹ | ç›®æ ‡/ç‰¹ç‚¹ | ç¤ºä¾‹æ¨¡å¼ |
| --- | --- | --- |
| **æ¼”ç»æ¨ç† (Deduction)** | ä»ä¸€èˆ¬æ€§è§„åˆ™å’Œå‰ææ¨å¯¼å‡ºå¿…ç„¶çš„ã€ç‰¹æ®Šçš„ç»“è®ºã€‚ç»“è®ºçš„æ­£ç¡®æ€§ç”±å‰æä¿è¯ã€‚ | å‰æ 1: æ‰€æœ‰çš„é¸Ÿéƒ½ä¼šé£ã€‚ å‰æ 2: éº»é›€æ˜¯é¸Ÿã€‚ ç»“è®º: éº»é›€ä¼šé£ã€‚ |
| **å½’çº³æ¨ç† (Induction)** | ä»ç‰¹æ®Šçš„äº‹å®æˆ–è§‚å¯Ÿä¸­æ¨å¯¼å‡ºä¸€èˆ¬æ€§çš„è§„åˆ™æˆ–ç»“è®ºã€‚ç»“è®ºå¯èƒ½æ­£ç¡®ï¼Œä½†ä¸ä¿è¯å¿…ç„¶æ­£ç¡®ã€‚ | è§‚å¯Ÿ 1: æˆ‘è§è¿‡çš„æ‰€æœ‰éº»é›€éƒ½ä¼šé£ã€‚ è§‚å¯Ÿ 2: æˆ‘è§è¿‡çš„æ‰€æœ‰é¸½å­éƒ½ä¼šé£ã€‚ ç»“è®º (å½’çº³): æ‰€æœ‰çš„é¸Ÿéƒ½ä¼šé£ã€‚ |
| **æº¯å› æ¨ç† (Abduction)** | ä»è§‚å¯Ÿåˆ°çš„ç»“æœå’Œå·²çŸ¥è§„åˆ™ï¼Œæ¨å¯¼å‡ºæœ€ä½³çš„è§£é‡Šæˆ–åŸå› ã€‚ç»“è®ºæ˜¯æœ€å¯èƒ½çš„è§£é‡Šã€‚ | è§„åˆ™: å¦‚æœä¸‹é›¨ï¼Œåœ°é¢å°±ä¼šæ¹¿ã€‚ ç»“æœ: åœ°é¢æ¹¿äº†ã€‚ ç»“è®º (æº¯å› ): å¯èƒ½æ˜¯ä¸‹é›¨äº†ã€‚ |

![alt text](pics/image5.png)

**Our main goal is to promote research on non-deductive reasoning and highlight the differences and challenges.**

| æ¨ç†æ¨¡å¼ | ç‰¹ç‚¹ | ç¤ºä¾‹ |
| --- | --- | --- |
| **ä¸¥æ ¼/å•è°ƒæ¨ç† (Strict/Monotonic)** | ç»“è®ºæ˜¯å¿…ç„¶çš„ã€‚æ–°çš„ä¿¡æ¯ä¸ä¼šæ”¹å˜ç»“è®ºã€‚ | å‰æ: æ‰€æœ‰äººéƒ½ä¼šæ­»ã€‚ å‰æ: è‹æ ¼æ‹‰åº•æ˜¯äººã€‚ ç»“è®º: è‹æ ¼æ‹‰åº•ä¼šæ­»ã€‚ |
| **å¯åºŸæ­¢/éå•è°ƒæ¨ç† (Defeasible/Non-monotonic)** | ç»“è®ºæ˜¯æ¨æµ‹æ€§çš„ã€æš‚å®šçš„ã€‚æ–°çš„ä¿¡æ¯å¯èƒ½ä½¿ç»“è®ºå¤±æ•ˆã€‚ | åˆå§‹çŸ¥è¯†ï¼š é¸Ÿä¼šé£ã€‚ æ¨è®ºï¼š ä¼é¹…æ˜¯ä¸€åªé¸Ÿï¼Œæ‰€ä»¥ä¼é¹…ä¼šé£ã€‚ æ–°ä¿¡æ¯ï¼ˆåºŸæ­¢ï¼‰ï¼š ä¼é¹…ä¸ä¼šé£ã€‚ æœ€ç»ˆç»“è®ºï¼š ä¼é¹…ä¸ä¼šé£ã€‚ |

![alt text](pics/image6.png)

### 2.3 Potentials, Challenges, and Requirements of NLR

**Potentials**:

- Better human-comuter interaction inferface

- Opens a door to play with defeasible reasoning

**Challenges**:

- Nature language suffer from ambiguity and variety

- Supervised data of inference is difficult to obtain

- The step of reasoning is diverse

**Requirements**:

- Knowledge obtain

- Knowledge understanding

- Knowledge inference

## 3 Why PLMs For NLR

PLMs can learn to perform multi-step reasoning from supervised data or fewshot demonstrations. Their capabilities of natural language understanding, generalization, and leveraging implicit knowledge make them promising to deal with arbitrary natural language, commonsense knowledge, and defeasible reasoning.

## 4 Methodologies of NLR

| ç‰¹å¾ | ç«¯åˆ°ç«¯æ¨ç† (End-to-End) | å‰å‘æ¨ç† (Forward Reasoning) | åå‘æ¨ç† (Backward Reasoning) |
| -- | -- | -- | -- |
| æ¨ç†æ–¹å‘ | éšå¼/æ— æ–¹å‘ (Input $\rightarrow$ Output) | æ•°æ®é©±åŠ¨ï¼š ä»è¯æ®/å‰æ $\rightarrow$ ç»“è®º | ç›®æ ‡é©±åŠ¨ï¼š ä»ç»“è®º/ç›®æ ‡ $\rightarrow$ æ‰€éœ€å‰æ | 
| é€»è¾‘æ­¥éª¤ | éšå¼ï¼Œæ¨¡å‹å†…éƒ¨å®Œæˆï¼Œä¸å±•ç¤ºã€‚ | æ˜¾å¼ï¼ŒæŒ‰é¡ºåºç”Ÿæˆä¸­é—´æ­¥éª¤/ç»“è®ºã€‚ | æ˜¾å¼ï¼Œå°†ç›®æ ‡åˆ†è§£ä¸ºå­ç›®æ ‡æˆ–æ‰€éœ€æ¡ä»¶ã€‚| 
| å¯è§£é‡Šæ€§ | ä½ (é»‘ç®±)ï¼Œéš¾ä»¥è¿½æº¯æ¨ç†è·¯å¾„ã€‚ | ä¸­/é«˜ (æä¾›æ€ç»´é“¾ CoT)ï¼Œè¿‡ç¨‹ç›¸å¯¹é€æ˜ã€‚ | é«˜ (æä¾›åˆ†è§£ç»“æ„æˆ–è¯æ˜è·¯å¾„)ï¼Œç›®æ ‡æ¸…æ™°ã€‚|
| å¯¹å¤æ‚ä»»åŠ¡çš„é²æ£’æ€§ | å·®ï¼Œéš¾ä»¥å¤„ç†å¤šæ­¥æ¨ç†å’Œä¾‹å¤–ã€‚ | ä¸­ï¼Œå®¹æ˜“å—æ—©æœŸé”™è¯¯å½±å“ï¼ˆè´ªå©ªæœç´¢ï¼‰ã€‚ | å¼ºï¼Œé€šè¿‡åˆ†è§£ç®¡ç†å¤æ‚æ€§ï¼Œä¸“æ³¨è§£å†³å­ç›®æ ‡ã€‚| 
| å…¸å‹åº”ç”¨ | ç®€å•çš„åˆ†ç±»ä»»åŠ¡ã€å•æ­¥é—®ç­”ã€‚ | å¤šæ­¥æ¼”ç»æ¨ç†ã€å¸¸è¯†æ¨ç†ã€‚ | å¤æ‚çš„å¤šè·³é—®ç­”ã€é€»è¾‘è¯æ˜ã€è¯Šæ–­ã€‚| 
| LLMå®ç°æŠ€æœ¯ | æ ‡å‡†æç¤º (Standard Prompting) | æ€ç»´é“¾ (Chain-of-Thought, CoT) | é—®é¢˜åˆ†è§£ (Question Decomposition)ã€åå‘é“¾ (Backward Chaining) |

![alt text](pics/image8.png)

![alt text](pics/image7.png)

### 4.1 End to End Reasoning


Rely heavily on handcrafts, introducing strong prior assumptions, which may hurt the generalization ability to other tasks.

### 4.2 Forward Reasoning

### 4.3 Backward Reasoning

### 4.4 Summary

## 5 NLR Benchmarks

### 5.1 Classical Logical Reasoning

#### 5.1.1 Deductive Reasoning

![alt text](pics/image9.png)

- **Inference**: reason the conclusion given the premises in a single step

- **Theoerm proving**: predict whether the given proposition is true or false with the given knowledge bases

- **Reasoning path generation**: an interpretable task that can be complementary to multi-step reasoning

#### 5.1.2 Defeasible Reasoning

![alt text](pics/image10.png)

- **Deductive Reasoning**

- **Abductive Reasoning**

### 5.2 Nature Language Inference

### 5.3 Multi-hop Question Answering

### 5.4 Commonsense Reasoning

### 5.5 Complex Reasoning

### 5.6 Others

## 6 Discussion

### 6.1 Open Questions

### 6.2 Limitations

### 6.3 Future