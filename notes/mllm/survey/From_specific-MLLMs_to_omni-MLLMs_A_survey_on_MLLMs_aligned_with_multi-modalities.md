# From Specific-MLLMs to Omni-MLLMs: A Survey on MLLMs Aligned with Multi-modalities

**Author**: Shixin Jiang1, Jiafeng Liang1, Jiyuan Wang1, Xuan Dong1, Heng Chang3  Weijiang Yu3, Jinhua Du4, Ming Liu1,2*, Bing Qin1,2 

**Publish Date**: 2025 

**Add Date**: 2025.10.15 

**Journal/Meeting**: Findings of the Association for Computational Linguistics: ACL 2025 

**Star**: ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ

**PDF**: [From Specific-MLLMs to Omni-MLLMs: A Survey on MLLMs Aligned with Multi-modalities](original_files/Jiang_2025_From_specific-MLLMs_to_omni-MLLMs_A_survey_on_MLLMs_aligned_with_multi-modalities.pdf)

## 1 Introduction

**æ ¸å¿ƒé—®é¢˜**â€‹ï¼šä¸ºäº†è§£å†³ç°å®ä¸–ç•Œä¸­å¤æ‚çš„å¤šæ¨¡æ€ä»»åŠ¡ï¼Œç ”ç©¶ç„¦ç‚¹æ­£ä»å¤„ç†å•ä¸€æ¨¡æ€çš„ç‰¹å®šMLLMsï¼ˆSpecific-MLLMsï¼‰è½¬å‘èƒ½å¤Ÿå®ç°å…¨æ¨¡æ€ç†è§£å’Œç”Ÿæˆçš„Omni-MLLMsã€‚

**â€‹Omni-MLLMsçš„å®šä¹‰ä¸ç›®æ ‡â€‹**

- **â€‹ç›®æ ‡**â€‹ï¼šçªç ´ç‰¹å®šéè¯­è¨€æ¨¡æ€çš„é™åˆ¶ï¼Œå°†å„ç§éè¯­è¨€æ¨¡æ€æ˜ å°„åˆ°å¤§å‹è¯­è¨€æ¨¡å‹çš„åµŒå…¥ç©ºé—´ä¸­ï¼Œä½¿å•ä¸ªæ¨¡å‹èƒ½å¤Ÿç†è§£å’Œäº¤äº’ä»»æ„ç»„åˆçš„æ¨¡æ€ã€‚

- **â€‹èƒ½åŠ›**â€‹ï¼šä¸ä»…èƒ½æ‰§è¡Œå¤šç±»å•æ¨¡æ€ä»»åŠ¡ï¼Œè¿˜èƒ½å®Œæˆæ¶‰åŠä¸¤ä¸ªæˆ–æ›´å¤šéè¯­è¨€æ¨¡æ€çš„è·¨æ¨¡æ€ä»»åŠ¡ã€‚

**â€‹å‘å±•é©±åŠ¨åŠ›**

- **â€‹æ¨¡æ€æ•°é‡**â€‹ï¼šä»å¤„ç†è§†è§‰å’ŒéŸ³é¢‘ï¼Œæ‰©å±•åˆ°3Dã€IMUç­‰ï¼Œç›´è‡³åŒæ—¶å¤„ç†å…«ç§æ¨¡æ€ã€‚

- **â€‹äº¤äº’èƒ½åŠ›**â€‹ï¼šä»è·¨æ¨¡æ€æ¨ç†ï¼ˆå¦‚3D-å›¾åƒã€éŸ³é¢‘-å›¾åƒï¼‰æ‰©å±•åˆ°è·¨æ¨¡æ€ç”Ÿæˆï¼ˆå¦‚æ ¹æ®äº¤ç»‡çš„éŸ³é¢‘å’Œå›¾åƒä¸Šä¸‹æ–‡ç”ŸæˆéŸ³é¢‘å’Œå›¾åƒï¼‰ï¼Œè¶‹å‘äºâ€œä»»æ„åˆ°ä»»æ„â€çš„æ¨¡å‹ã€‚

- **â€‹åº”ç”¨åœºæ™¯**â€‹ï¼šæ¶µç›–å®æ—¶å¤šæ¨¡æ€è¯­éŸ³äº¤äº’ã€ä¸–ç•Œæ¨¡æ‹Ÿã€å¤šä¼ æ„Ÿå™¨è‡ªåŠ¨é©¾é©¶ç­‰ã€‚

**â€‹æœ¬æ–‡è´¡çŒ®â€‹**

- **â€‹é¦–ä¸ªå…¨é¢ç»¼è¿°**â€‹ï¼šé¦–æ¬¡ä¸“é—¨é’ˆå¯¹Omni-MLLMsçš„ç³»ç»Ÿæ€§ç»¼è¿°ã€‚

- **â€‹ç»†è‡´åˆ†ç±»æ³•**â€‹ï¼šæå‡ºäº†ä¸€ä¸ªç»†è‡´çš„åˆ†ç±»æ³•ï¼ˆè§å›¾2ï¼‰ã€‚

- **â€‹æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘â€‹**ï¼šæŒ‡å‡ºäº†å½“å‰Omni-MLLMsçš„ä¸»è¦æŒ‘æˆ˜å¹¶å±•æœ›äº†æœªæ¥ç ”ç©¶ã€‚

![alt text](pics/image8.png)

## 2 Omni-MLLM Architecture

![alt text](pics/image9.png)

### 2.1 Multi-modalities Encoding

#### 2.1.1 Continuous Encoding

Continuous encoding refers to encoding the modality into the continuous feature space.

- **Heterogeneous Encoders**: $F_{x}=\mathrm{SpecificEncoder}(X), F_{x}\in\mathbb{R}_{x}$. $\mathrm{SpecificEncoder}$ refers to different modality-specific encoders used in Omni-MLLMs. These modality-specific encoders encode different modalities ($X$) into distinct feature spaces ($\mathbb{R}_{x}$) as ($F_x$). 

- **å…¬å¼ (2)**: $F_{x}=\mathrm{PreAlignEncoder}(X), F_{x}\in\mathbb{R}_{uni}$ã€‚æ­¤å…¬å¼ä»£è¡¨ä½¿ç”¨é¢„å¯¹é½ç¼–ç å™¨çš„è¿ç»­ç¼–ç æ–¹æ³•ã€‚å®ƒå°†ä¸åŒçš„æ¨¡æ€ ($X$) ç¼–ç  ($F_x$) åˆ°ç›¸åŒçš„ç‰¹å¾ç©ºé—´ ($\mathbb{R}_{uni}$)ã€‚$\mathrm{PreAlignEncoder}$ æŒ‡çš„æ˜¯é‚£äº›èƒ½ç»Ÿä¸€ç¼–ç å¤šç§æ¨¡æ€çš„ç¼–ç å™¨ï¼Œä¾‹å¦‚ LanguageBind æˆ– ImageBindã€‚


#### 2.1.2 Discrete Encoding

#### 2.1.3 Hybrid Encoding

### 2.2. Multi-modalities Alignment

#### 2.2.1 Projection Alignment

#### 2.2.2 Embedding Alignment

### 2.3 Multi-modalities Interaction

### 2.4 Multi-modalities Generation

![alt text](pics/image10.png)

- **Text-based**

- **Modality-Token-based**

- **Representation-based**

## 3 Omni-MLLM Training

### 3.1 Multi-modalities Alignment Pre-training

#### 3.1.1 Input Alignment

#### 3.1.2 Output Alignment

#### 3.2 Multi-modalities Instruction Fine-tuning

### 3.3 Other Train Recipes

## 4 Data Construction and Evaluation

### 4.1 Training Data

- **Alignment Data**

- **Instruction Data**

### 4.2 Benchmark

- **Uni-modal Understanding**

- **Uni-modal Generation**

- **Cross-modal Understanding**

- **Cross-modal Generation**

## 5 Challenges and Future Directions

### 5.1 Expansion of modalities

- **Training efficiency**

- **Catastrophic forgetting**

- **Low-resource modalities**

### 5.2 Cross-modal capabilities**

- **Long Context**

- **Modality Bias**

- **Temporal Alignment**

- **Data and Benchmark**

### 5.3 Application scenarios

- **Real-time Multi-modalities Interaction**

- **Comprehensive Planning**

- **World Simulator**

## 6 Conclusion
